{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fed6502-b63d-4c0f-b479-16a4a08b6fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# import subprocess\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "# output = result.stdout\n",
    "# for line in output.splitlines():\n",
    "#     if '=' in line:\n",
    "#         var, value = line.split('=', 1)\n",
    "#         os.environ[var] = value\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# # 设置环境变量\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# # 打印环境变量以确认设置成功\n",
    "# print(os.environ.get('HF_ENDPOINT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e99399-eb32-4ebc-8ceb-33ecf0e059a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ced023-fa39-4c26-a159-fb62789d4b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 GPT-2 分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dnagpt/gene_eng_gpt2_summary\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # 设置填充标记为 EOS 标记\n",
    "\n",
    "# 6. 加载 GPT-2 模型\n",
    "model = GPT2LMHeadModel.from_pretrained(\"dnagpt/gene_eng_gpt2_summary\")\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c0f30c-4da3-4b98-80b0-95b708a2942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sequence(sequence):\n",
    "    # 定义字符集（所有字符都假设为大写）\n",
    "    dna_chars = set('ACGT')\n",
    "    protein_chars = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "    english_chars = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789 ,.!?:;-\"\\'()')\n",
    "\n",
    "    # 去除空格并检查长度\n",
    "    sequence = sequence.strip()  # \n",
    "    \n",
    "    # 检查是否为DNA序列\n",
    "    if all(c in dna_chars for c in sequence):\n",
    "        return \"DNA\"\n",
    "    \n",
    "    # 检查是否为蛋白质序列\n",
    "    if all(c in protein_chars for c in sequence):\n",
    "        return \"Protein\"\n",
    "    \n",
    "    # 检查是否为英文文本（允许大小写字母、数字及常见标点符号）\n",
    "    if all(c in english_chars for c in sequence):\n",
    "        return \"English\"\n",
    "    \n",
    "    # 如果不符合上述任何条件，则无法明确分类\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdb7866-0520-40c4-9875-5812879d676a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19413"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获得DNA和英文词表  只要长度2个及以上的词\n",
    "word_dict = tokenizer.get_vocab()\n",
    "\n",
    "DNA_token_list = []\n",
    "\n",
    "for word in word_dict:\n",
    "    word_type = classify_sequence(word)\n",
    "    if \"DNA\"==word_type:\n",
    "        DNA_token_list.append(word)\n",
    "\n",
    "len(DNA_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9afe92-1848-45c3-a597-a8393dc9d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LogitsProcessorList, LogitsProcessor\n",
    "import torch\n",
    "\n",
    "class DNAOnlyLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, allowed_tokens, tokenizer):\n",
    "        self.allowed_token_ids = tokenizer.convert_tokens_to_ids(allowed_tokens)\n",
    "    \n",
    "    def __call__(self, input_ids, scores):\n",
    "        # 创建掩码，将不允许的 token 的分数设为 -inf\n",
    "        mask = torch.full_like(scores, float(\"-inf\"))\n",
    "        mask[:, self.allowed_token_ids] = 0\n",
    "        scores += mask\n",
    "        return scores\n",
    "\n",
    "def get_summary_with_constraints(text, DNA_token_list):\n",
    "    # 确保输入文本的预处理\n",
    "    text = text[0:250] #截断处理,防止截掉summary特定符号\n",
    "    text = text.strip() + \" TL;DR:\"\n",
    "    \n",
    "    # 对输入文本进行编码\n",
    "    encoded_input = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=256,  # 输入文本的最大长度\n",
    "    )\n",
    "\n",
    "    # 创建 DNA 限制的 LogitsProcessor\n",
    "    logits_processor = LogitsProcessorList([\n",
    "        DNAOnlyLogitsProcessor(DNA_token_list, tokenizer)\n",
    "    ])\n",
    "    \n",
    "    # 使用 max_new_tokens 控制生成长度\n",
    "    output = model.generate(\n",
    "        input_ids=encoded_input[\"input_ids\"],\n",
    "        attention_mask=encoded_input[\"attention_mask\"],\n",
    "        max_new_tokens=6,       # 控制生成的新增文本长度\n",
    "        num_beams=5,             # 控制生成文本的多样性\n",
    "        logits_processor=logits_processor,\n",
    "        no_repeat_ngram_size=3,  # 避免生成重复内容\n",
    "        early_stopping=True,     # 提前终止生成\n",
    "    )\n",
    "    \n",
    "    # 对生成的输出进行解码\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 提取生成的摘要部分\n",
    "    summary = generated_text[len(text)+len(encoded_input[\"input_ids\"][0])-1:].strip() #字符长度+多出来的空格-1\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc600a88-95ce-4797-9a11-3cfc51abc17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G TTATAGCC TGTGAGAG TATG TTGGTGG TTTG\n"
     ]
    }
   ],
   "source": [
    "# 示例用法\n",
    "#test_text = \"The DNA sequence analysis showed remarkable results.\"\n",
    "test_text = \"GTTATAACCTGTGAGAGTATGTTGGCGGTTTGTTGCACCTACCTTTCAAACCTCTTGTTCTTCCTGTGATTTATTTGAGGCACTCAAGTGGACAGAGACCATGAGAAATTTGAGTGGAGGCCATGTCGAAGAGTTTGTCTTGGTGGGTTTCCCTACCACTCCTCCCTTCCAGCTGCTCCTCTTTGTCCTTTTCTTTGCAATTTACCTTCTGACATTGTTGGAGAATGCACTCATTGTCTTCACAATATGGCTCACTCCAAGCCTTCATCGCCCCATGTACTTTTTCCTTGGCCATCTTTCTTTCCTGGAGCTTTGGTACATCAACGTCACCATTCCTCAGCTCTTGGCAGCCTTTCTTACCCAGGATAGTAGAGTCTCCTATGTAGGTTGCATGACCCAACTCTACTTCTTTATTGCCTTAGCCTGTACTGAATGTGTGCTGTTGGCAGTTATGGCCTATGACCGC\"\n",
    "\n",
    "print(get_summary_with_constraints(test_text, DNA_token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ea1553-5086-40e1-a094-4e1d527dbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#读取第一层的数据\n",
    "json_str = open(\"p1_cluster_data_with_title.json\",\"r\").read()\n",
    "p1_cluster_data_with_title = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f22f95f-b931-408c-a171-7457ea64cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取第二层的数据\n",
    "json_str = open(\"p2_cluster_data.json\",\"r\").read()\n",
    "p2_cluster_data = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865fe3c4-86c7-4b23-b16d-f0500ef7540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_para_title_list(para_index_list):\n",
    "    para_title_list = []\n",
    "    for index in para_index_list:\n",
    "        para_title = p1_cluster_data_with_title[index][\"title\"].replace(\" \",\"\").strip()\n",
    "        para_title_list.append(para_title)\n",
    "    return para_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50aaaa6a-181b-4bfc-b52f-c632cd2314d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p2_title C ATTCATTC ATACATAC ATCC ATACATAC ATCC\n",
      "p2_title TC TATAGCC CCCG TACCCC TGCCC ACATT\n",
      "p2_title C ATACATTC ATACATTC ATACATCC ATACATAC ATC\n",
      "p2_title TC TATGGAA ACCATG TATTTG CCCC TTTCTAA\n",
      "p2_title C ATACATTC ATACATTC ATACATCC ATACATAC ATC\n",
      "p2_title TC TATGGCC AAGTAA AGTAGG TTGCTAC ATTATTTTTT\n",
      "p2_title C ATACATTC ATACATTC ATACATCC ATACATAC ATC\n",
      "p2_title AC TATTTGCC CCCTTTT TCCCC AATTTGG AATGCCC\n",
      "p2_title TC TATGGAA ACCACG ATT AC TATGGAA\n",
      "p2_title AC TATACG TGTGTGTC TATGTGTGTG AGCATGG AGGGG\n",
      "p2_title TC TATGGCC CCC TCAG AACGG TCTGTG\n",
      "p2_title A A A AAA AAA AAA\n",
      "p2_title TC TATGGAA ACC TCAACC ACAAC ATTAAAA\n",
      "p2_title A A A G A G\n",
      "p2_title AG TTTATCC CCCCCCCC CCCCCC AGTGC TGGCCGGG\n",
      "p2_title C AT C AT A C\n",
      "p2_title ACC CCCCCC ACC CCCCCCCC CCCCCC ACC\n",
      "p2_title C ATACATTC ATACATTC ATACATCC ATACATAC ATC\n",
      "p2_title AC TATAAGCC ACC ACAAGG TGAGCGC ATATGAG\n",
      "p2_title AC TATGGAA ACC AATCAGCC ACAACATT AAAAAAAA\n",
      "p2_title TC TATGGAA ACC ATTTTAGCC ACAACATT AAAACC\n",
      "p2_title AC TATGGAA ACC AATCAGCC ACAACATT AAAAAAAA\n",
      "p2_title AC TATGGAA ACC GCGATC AGCC ACAACATT\n",
      "p2_title TC TATGGAA ACC TTACCG TGGCC ACGC\n",
      "p2_title AC TCACTGCAACC TCCCAGG TTCAAGTGATTCTCCTGCC TCAGCCTCCCAAGTAGC TGGGATTACAGGC\n",
      "p2_title TC TATGGAA ACC AATCAGC TC TATGGAA\n",
      "p2_title ATT AC TATTGCC CCCTTTT TCCCC AGTCC\n",
      "p2_title AG TTTATCC CCCC CCCCG ACTATGG AAAG\n",
      "p2_title TC TATGGAA ACC AC TATGGAA ACC\n",
      "p2_title TC TATAGCC AAGACG AGCCC TAACCC TC\n",
      "p2_title AC TATTTGCC ATT TC TATTGCC ATT\n",
      "p2_title C AT C AT A C\n",
      "p2_title TC TATGGAA ACC AATCAGCC ACAACATT AAAACC\n",
      "p2_title AC TATTTGCC CCCTTTT CCCCCC GC ACCCC\n",
      "p2_title A A A G A G\n",
      "p2_title AC TATGGAA ATCAACC ACAACATT AAAACC AG\n",
      "p2_title TC TATGGAA TACTAC GC TATGGAA TAC\n",
      "p2_title AC TATTTTCC CCCC AATTTGG AG TATAGCC\n"
     ]
    }
   ],
   "source": [
    "#加入摘要\n",
    "p2_cluster_data_with_title = []\n",
    "for item in p2_cluster_data:\n",
    "    para_index_list = item[\"para_list\"]\n",
    "    para_title_list = get_para_title_list(para_index_list)\n",
    "\n",
    "    para_title_list_join_str =  \"\".join(para_title_list)\n",
    "    p2_title = get_summary_with_constraints(para_title_list_join_str, DNA_token_list)\n",
    "\n",
    "    print(\"p2_title\", p2_title)\n",
    "    item[\"title\"] = p2_title\n",
    "    p2_cluster_data_with_title.append(item)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257925c5-0104-4750-b583-81c448e81765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC CCCCCCCC CCCGCC CCCC CCCGCC CCCC\n"
     ]
    }
   ],
   "source": [
    "test_text = \"AGTAGCCTCAGGACACAGGGGTATGGGGACTACCTTGATGGCCTTCTTGCTGCCCTTGATCTTCTCAATCTTGGCCTGGGCCAAGGAGACCTTCTCTCCAATGGCCTGCACCTGGCTCCGGCTCTGCTCTACCTGCTGGGAGATCCTGCCATGGAGAAGATCACAGAGGCTGGGCTGCTCCCCACCCTCTGCACACCTCCTGCTTCTAACAGCAGAGCTGCCAGGCCAGGCCCTCAGGCAAGGGCTCTGAAGTCAGGGTCACCTACTTGCCAGGGCCGATCTTGGTGCCATCCAGGGGGCCTCTACAAGGATAATCTGACCTGCAGGGTCGAGGAGTTGACGGTGCTGAGTTCCCTGCACTCTCAGTAGGGACAGGCCCTATGCTGCCACCTGTACATGCTATCTGAAGGACAGCCTCCAGGGCACACAGAGGATGGTATTTACACATGCACACATGGCTACTGATGGGGCAAGCACTTCACAACCTGGCTCCGGCTCTGCTCTACCTGCTGGGAGATCCTGCCATGGAGAAGATCACAGAGGCTGGGCTGCTCCCCACCCTCTGCACACCTCCTGCTTCTAACAGCAGAGCTGCCAGGCCAGGCCCTCAGGCAAGGGCTCTGAAGTCAGGGTCACCTACTTGCCAGGGCCGATCTTGGTGCCATCCAGGGGGCCTCTACAAGGATAATCTGACCTGCAGGGTCGAGGAGTTGACGGTGCTGAGTTCCCTGCACTCTCAGTAGGGACAGGCCCTATGCTGCCACCTGTACATGCTATCTGAAGGACAGCCTCCAGGGCACACAGAGGATGGTATTTACACATGCACACATGGCTACTGATGGGGCAAGCACTTCACAACCCCTCATGATCACGTGCAGCAGACAATGTGGCCTCTGCAGAGGGGGAACGGAGACCGGAGGCTGAGACTGGCAAGGCTGGACCTGAGTGTCGTCACCTAAATTCAGACGGGGAACTGCCCCTGCACATACTGAACGGCTCACTGAGCAAACCCCGAGTCCCGACCACCGCCTCAGTGTGGTCTAGCTCCTCACCTGCTTCCATCCTCCCTGGTGCGGGGTGGGCCCAGTGATATCAGCTGCCTGCTGTTCCCCAGATGTGCCAAGTGCATTCTTGTGTGCTTGCATCTCATGGAACGCCATTTCCCCAGACATCCCTGTGGCTGGCTCCTGATGCCCGAGGCCCAAGTGTCTGATGCTTTAAGGCACATCACCCCACTCATGCTTTTCCATGTTCTTTGGCCGCAGCAAGGCCGCTCTCACTGCAAAGTTAACTCTGATGCGTGTGTAACACAACATCCTCCTCCCAGTCGCCCCTGTAGCTCCCCTACCTCCAAGAGCCCAGCCCTTGCCCACAGGGCCACACTCCACGTGCAGAGCAGCCTCAGCACTCACCGGGCACGAGCGAGCCTGTGTGGTGCGCAGGGATGAGAAGGCAGAGGCGCGACTGGGGTTCATGAGGAAGGGCAGGAGGAGGGTGTGGGATGGTGGAGGGGTTTGAGAAGGCAGAGGCGCGACTGGGGTTCATGAGGAAAGGGAGGGGGAGGATGTGGGATGGTGGAGGGGCTGCAGACTCTGGGCTAGGGAAAGCTGGGATGTCTCTAAAGGTTGGAATGAATGGCCTAGAATCCGACCCAATAAGCCAAAGCCACTTCCACCAACGTTAGAAGGCCTTGGCCCCCAG\"\n",
    "print(get_summary_with_constraints(test_text, DNA_token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f97f4f2-85ea-469a-8deb-0c6a2f30ca9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 p2_cluster_data_with_title.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 保存到 JSON 文件\n",
    "with open(\"p2_cluster_data_with_title.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(p2_cluster_data_with_title, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"数据已保存到 p2_cluster_data_with_title.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02eea52-d01f-4b64-a3dc-945003761c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
